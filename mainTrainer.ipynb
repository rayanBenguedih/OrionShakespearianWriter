{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataBuilder as db\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import shakespearianModelOrion as smo\n",
    "\n",
    "import openai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetBuilder = db.dataTokenizerBuilder(filename='shakespear.txt', path_to_file='https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt', seq_length=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCHSIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "\n",
    "dataset = datasetBuilder.build_dataset(batch_size=BATCHSIZE, buffer_size=BUFFER_SIZE)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = datasetBuilder.get_char2idx()\n",
    "\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "\n",
    "\n",
    "embedding_dim = 256\n",
    "\n",
    "rnn_units = 1024\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smo.Orion(vocab_size, embedding_dim, rnn_units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"orion_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     multiple                  16896     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 multiple                  3938304   \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  67650     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4022850 (15.35 MB)\n",
      "Trainable params: 4022850 (15.35 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = smo.tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sample_indices = smo.tf.squeeze(sample_indices, axis=-1).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32,  1, 25, 38, 56, 34, 45, 62, 27, 60, 45, 57, 48, 12, 20, 25, 23,\n",
       "       58,  7, 19, 22, 34, 44,  7,  6,  7, 46, 25, 55,  6, 58, 42, 48,  3,\n",
       "       55, 26, 26, 29,  0, 26, 47,  3, 50, 18, 17, 56, 35, 47,  8, 15, 40,\n",
       "       40, 52, 29, 55, 33, 54, 23, 37, 64, 23, 30, 36, 51, 62, 54, 46, 56,\n",
       "       37, 19, 37, 42, 10, 62, 47, 30,  2,  4, 37, 50, 36, 19, 39, 22, 35,\n",
       "        9, 34, 13, 49, 32, 42, 53, 43,  0, 61, 44, 26, 44, 48, 40],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         4.1913843\n"
     ]
    }
   ],
   "source": [
    "loss = smo.tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "mean_loss = example_batch_loss.numpy().mean()\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", mean_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.11425"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smo.tf.exp(example_batch_loss).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = smo.os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = smo.tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 162s 933ms/step - loss: 2.7046\n",
      "Epoch 2/20\n",
      "172/172 [==============================] - 154s 897ms/step - loss: 1.9955\n",
      "Epoch 3/20\n",
      "172/172 [==============================] - 159s 924ms/step - loss: 1.7397\n",
      "Epoch 4/20\n",
      "172/172 [==============================] - 157s 910ms/step - loss: 1.5774\n",
      "Epoch 5/20\n",
      "172/172 [==============================] - 155s 899ms/step - loss: 1.4713\n",
      "Epoch 6/20\n",
      "172/172 [==============================] - 154s 896ms/step - loss: 1.4004\n",
      "Epoch 7/20\n",
      "172/172 [==============================] - 151s 878ms/step - loss: 1.3449\n",
      "Epoch 8/20\n",
      "172/172 [==============================] - 154s 894ms/step - loss: 1.2989\n",
      "Epoch 9/20\n",
      "172/172 [==============================] - 158s 920ms/step - loss: 1.2567\n",
      "Epoch 10/20\n",
      "172/172 [==============================] - 151s 874ms/step - loss: 1.2161\n",
      "Epoch 11/20\n",
      "172/172 [==============================] - 151s 878ms/step - loss: 1.1767\n",
      "Epoch 12/20\n",
      "172/172 [==============================] - 150s 871ms/step - loss: 1.1347\n",
      "Epoch 13/20\n",
      "172/172 [==============================] - 150s 871ms/step - loss: 1.0917\n",
      "Epoch 14/20\n",
      "172/172 [==============================] - 153s 887ms/step - loss: 1.0449\n",
      "Epoch 15/20\n",
      "172/172 [==============================] - 155s 902ms/step - loss: 0.9972\n",
      "Epoch 16/20\n",
      "172/172 [==============================] - 154s 893ms/step - loss: 0.9454\n",
      "Epoch 17/20\n",
      "172/172 [==============================] - 153s 890ms/step - loss: 0.8934\n",
      "Epoch 18/20\n",
      "172/172 [==============================] - 180s 1s/step - loss: 0.8405\n",
      "Epoch 19/20\n",
      "172/172 [==============================] - 182s 1s/step - loss: 0.7905\n",
      "Epoch 20/20\n",
      "172/172 [==============================] - 182s 1s/step - loss: 0.7446\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('OrionModel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "one_step_model = smo.singleStep(model, datasetBuilder.get_idx2char(), datasetBuilder.get_char2idx())\n",
    "\n",
    "\n",
    "\n",
    "def mainLoop(LEN=800):\n",
    "    start = time.time()\n",
    "    states = None\n",
    "    next_char = smo.tf.constant(['ROMEO:'])\n",
    "    result = [next_char]\n",
    "\n",
    "    for i in range(LEN):\n",
    "        next_char, states = one_step_model.gen_step(next_char, states=states)\n",
    "        result.append(next_char)\n",
    "    result = smo.tf.strings.join(result)\n",
    "    end = time.time()\n",
    "    text = result[0].numpy().decode('utf-8')\n",
    "\n",
    "    with open(\"shakespeare.txt\", \"w\") as f:\n",
    "        f.write(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ROMEO:\\nSo say I read to her:\\nWidow, I spy abuse: more present you will lack\\nAnd make the learn and ox our lands and\\nenvyorn counsel! to bring him not\\nUpon my garliam-like a footman by:\\nby me trow, this is a Jaunt of wooing,\\nOn seduced with the law hath forsor ever\\nI was agains with invises; once\\nand get him hence in one of Paulina,\\nFor such a life, above the minsmen, clay\\nand come against your cousin?\\n\\nISABELLA:\\nI am fair a head so sir;\\nNay, therefore follower more villain!\\n\\nDUKE VINCENTIO:\\n\\nHORTENSIO:\\nI do not: mose keen in a made,\\nAnd then I'll have them must die time of kings\\nand treason born: so strive me one.\\n\\nLUCENTIO:\\nAway! so.\\nWho was A noble gentleman and a\\nhorse, misinks, for a fellor more, name\\nI come abatement where stands you are.\\n\\nISABELLA:\\nI am sweet you, sir; and, none, but I bid thee, sir:\\nHear me, you mean now to command me will\\nI shall procease with cloids in Such and mendon.\\n\\nDUKE VINCENTIO:\\nMore than that officer, and they will not\\nBe secret: take up my father's greatnes\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mainLoop(LEN=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "API_KEY = open(\"APIKEY.txt\", \"r\").read()\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Setting:**  \n",
      "The curtains rise to reveal a grand theater stage designed to resemble a medieval European town square. Stone buildings with flickering lanterns frame the backdrop, creating a cozy and mysterious atmosphere. A soft glow from the moonlight filters through the windows, casting shadows on the cobbled floor below. The sound of distant laughter and clinking of glasses can be heard from a nearby tavern, adding to the ambiance of the scene.\n",
      "\n",
      "**Scene:**  \n",
      "In the center of the stage, Romeo and Bianca stand facing each other, their expressions filled with passion and a hint of conflict. Bianca's handmaid, Kate, lingers close by, her eyes shifting between the two lovers. Leontes, a nobleman with a stern demeanor, approaches them, a look of curiosity on his face. Meanwhile, a page scurries across the stage, carrying a bundle of letters in hand, eager to deliver them to the rightful recipients. Petruchio and Hortensio engage in a lively discussion, gesturing animatedly as they debate a matter of importance. Ariel, an ethereal spirit, floats gracefully above the scene, observing the various interactions with a look of wisdom in his eyes. Lucientio and Antonio share a private moment, their voices lowered as they converse about matters unknown to the audience.\n",
      "\n",
      "**Context:**  \n",
      "The scene unfolds in a bustling town square at dusk, where the lives of the characters intersect in a web of love, deceit, and intrigue. Romeo's exclamation of frustration hints at a conflict brewing between him and his brother, while Bianca's sharp words reveal hidden tensions within their relationship. Leontes' sudden appearance adds another layer of complexity to the scene, as he questions the motives of those around him. The arrival of the page with a bundle of letters introduces a sense of urgency and impending revelation, hinting at secrets waiting to be exposed. Meanwhile, Petruchio and Hortensio's animated discussion provides a moment of comic relief, contrasting with the more serious tones of the other conversations. Throughout it all, Ariel's watchful presence serves as a silent witness to the unfolding drama, his mystical aura adding an air of enchantment to the scene. As the characters navigate their tangled emotions and conflicting desires, the stage is set for a tale of love, betrayal, and redemption to play out in true Shakespearean fashion.\n",
      "\n",
      "\n",
      "Dialogue:\n",
      "\n",
      " ROMEO:\n",
      "The worst of drawing curse!\n",
      "And, brother, you are bound to praction.\n",
      "\n",
      "BIANCA:\n",
      "Fie, the contract with you! be so, belike!\n",
      "You unrevet see, sweet Kate, bear her sushianch;\n",
      "The 'ky's applovethen, if God bend making me a\n",
      "day, my sweet-ripent, iragerly;\n",
      "I will be ruled by oath ere once\n",
      "fer our liking!\n",
      "\n",
      "LEONTES:\n",
      "Why, my old wife?\n",
      "\n",
      "Page:\n",
      "Here, sirrah! Master, Back would confess,\n",
      "Before I have letters from deceit as been\n",
      "advised.\n",
      "\n",
      "PETRUCHIO:\n",
      "Signior Hercands sit, to make a petty bear\n",
      "my brother.\n",
      "\n",
      "AUTORYO:\n",
      "O! a jot i'll bustle; but some shall be pen\n",
      "it.\n",
      "\n",
      "ARIEL:\n",
      "Claudio, for either never what your life\n",
      "and the lanning bride; and the friend of my maid,\n",
      "How to device for beauty will endure,\n",
      "Great Rodeo, that you know me on;\n",
      "And no will conceit the humbly but\n",
      "Then at thy gait and shoulder sined is for my office\n",
      "Take' of a funeral bledied toward.\n",
      "\n",
      "LUCENTIO:\n",
      "I cannot say, Lord: Bianca, give me looks than she.\n",
      "\n",
      "ANTONIO:\n",
      "Why, then thou'rt broken from Bebbard; I come by Romeo:\n",
      "And that you love me, spe\n"
     ]
    }
   ],
   "source": [
    "text_to_send = open(\"shakespeare.txt\", \"r\").read()\n",
    "\n",
    "\n",
    "content = mainLoop(LEN=1000)\n",
    "\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a theater narrator that will be given a text, and have to create a setting, a scene and a context for the dialogues given pretending it's shakespear text, do not include the dialogues in the answer\"},\n",
    "        {\"role\": \"user\", \"content\": text_to_send},\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "print(\"\\n\\nDialogue:\\n\\n\", text_to_send)\n",
    "\n",
    "# Define the directory\n",
    "directory = \"history\"\n",
    "\n",
    "# Check if the directory exists, if not, create it\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Get the list of files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# If there are no files in the directory, create a new file named tmp0\n",
    "if not files:\n",
    "    new_file_name = \"tmp0\"\n",
    "else:\n",
    "    # If there are files, find the highest numbered file and increment its number for the new file\n",
    "    highest_num = max(int(file[3:]) for file in files if file.startswith(\"tmp\"))\n",
    "    new_file_name = f\"tmp{highest_num + 1}\"\n",
    "\n",
    "# Create the new file in the directory\n",
    "new_file_path = os.path.join(directory, new_file_name)\n",
    "with open(new_file_path, 'w') as new_file:\n",
    "    pass\n",
    "\n",
    "# Move the content from shakespear.txt to the new file\n",
    "with open(\"shakespeare.txt\", 'r') as old_file:\n",
    "    content = old_file.read()\n",
    "with open(new_file_path, 'w') as new_file:\n",
    "    new_file.write(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
